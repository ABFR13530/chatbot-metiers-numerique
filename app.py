import streamlit as st
import os
import tempfile

import google.generativeai as genai
from chromadb import Client
from chromadb.config import Settings
import chromadb

# â”€â”€ Loaders â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    import fitz  # PyMuPDF
except ImportError:
    fitz = None

try:
    import docx2txt
except ImportError:
    docx2txt = None

# â”€â”€ Page config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Conseiller MÃ©tiers du NumÃ©rique",
    page_icon="ğŸ’»",
    layout="centered"
)

st.markdown("""
<style>
    .profile-badge { display:inline-block; padding:4px 14px; border-radius:20px; font-size:13px; font-weight:600; margin-bottom:12px; }
    .badge-scolaire { background-color:#d0f0c0; color:#2d6a2d; }
    .badge-emploi { background-color:#cce5ff; color:#004085; }
    .badge-reconversion { background-color:#fff3cd; color:#856404; }
    .badge-indefini { background-color:#e2e3e5; color:#383d41; }
</style>
""", unsafe_allow_html=True)

# â”€â”€ Profils â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROFILS = {
    "scolaire": {
        "label": "ğŸ“ Ã‰lÃ¨ve / Ã‰tudiant",
        "badge_class": "badge-scolaire",
        "system": "Tu es un conseiller expert en orientation scolaire vers les mÃ©tiers du numÃ©rique. Tu t'adresses Ã  des Ã©lÃ¨ves et Ã©tudiants. Ton ton est encourageant, accessible et motivant. Tu proposes des pistes de formations, diplÃ´mes et expÃ©riences pratiques. RÃ©ponds toujours en franÃ§ais."
    },
    "emploi": {
        "label": "ğŸ” Demandeur d'emploi",
        "badge_class": "badge-emploi",
        "system": "Tu es un conseiller emploi spÃ©cialisÃ© dans les mÃ©tiers du numÃ©rique. Tu aides les personnes en recherche d'emploi Ã  identifier les mÃ©tiers porteurs, compÃ©tences recherchÃ©es et formations rapides. Ton ton est professionnel et bienveillant. RÃ©ponds toujours en franÃ§ais."
    },
    "reconversion": {
        "label": "ğŸ”„ Cadre en reconversion",
        "badge_class": "badge-reconversion",
        "system": "Tu es un coach expert en reconversion professionnelle vers le numÃ©rique. Tu valorises les compÃ©tences transverses des cadres. Tu proposes des passerelles mÃ©tier rÃ©alistes et des plans de transition concrets. RÃ©ponds toujours en franÃ§ais."
    },
    "indefini": {
        "label": "â“ Profil Ã  dÃ©finir",
        "badge_class": "badge-indefini",
        "system": "Tu es un conseiller en orientation gÃ©nÃ©rale sur les mÃ©tiers du numÃ©rique. Pose des questions pour mieux comprendre la situation de l'utilisateur avant de l'orienter. Sois curieux et bienveillant. RÃ©ponds toujours en franÃ§ais."
    }
}

# â”€â”€ Fonctions utilitaires â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_text_from_pdf(filepath):
    if fitz is None:
        return ""
    text = ""
    doc = fitz.open(filepath)
    for page in doc:
        text += page.get_text()
    return text

def extract_text_from_docx(filepath):
    if docx2txt is None:
        return ""
    return docx2txt.process(filepath)

def chunk_text(text, chunk_size=800, overlap=100):
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start += chunk_size - overlap
    return [c for c in chunks if len(c.strip()) > 50]

def get_embedding(text, api_key):
    genai.configure(api_key=api_key)
    result = genai.embed_content(
        model="models/embedding-001",
        content=text,
        task_type="retrieval_document"
    )
    return result["embedding"]

def get_query_embedding(text, api_key):
    genai.configure(api_key=api_key)
    result = genai.embed_content(
        model="models/embedding-001",
        content=text,
        task_type="retrieval_query"
    )
    return result["embedding"]

def build_vectorstore(texts, api_key):
    client = chromadb.Client()
    collection = client.create_collection("docs")
    for i, text in enumerate(texts):
        emb = get_embedding(text, api_key)
        collection.add(embeddings=[emb], documents=[text], ids=[f"chunk_{i}"])
    return collection

def search_docs(collection, query, api_key, n=4):
    emb = get_query_embedding(query, api_key)
    results = collection.query(query_embeddings=[emb], n_results=min(n, collection.count()))
    return results["documents"][0] if results["documents"] else []

def detect_profil(message, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        prompt = f"""Analyse ce message et dÃ©termine le profil parmi : scolaire, emploi, reconversion, indefini.
- scolaire : Ã©lÃ¨ve, Ã©tudiant, lycÃ©en, en Ã©tudes, orientation
- emploi : demandeur d'emploi, cherche du travail, chÃ´mage
- reconversion : cadre, manager, professionnel expÃ©rimentÃ©, changer de mÃ©tier
- indefini : pas assez d'Ã©lÃ©ments
Message : "{message}"
RÃ©ponds uniquement avec un mot parmi : scolaire, emploi, reconversion, indefini"""
        response = model.generate_content(prompt)
        profil = response.text.strip().lower()
        if profil in PROFILS:
            return profil
    except:
        pass
    msg = message.lower()
    if any(k in msg for k in ["Ã©tudiant", "lycÃ©e", "Ã©cole", "universitÃ©", "bac", "Ã©tudes"]):
        return "scolaire"
    if any(k in msg for k in ["emploi", "travail", "chÃ´mage", "cv", "recrutement"]):
        return "emploi"
    if any(k in msg for k in ["reconversion", "cadre", "manager", "expÃ©rience", "changer"]):
        return "reconversion"
    return "indefini"

def generate_response(user_input, profil_key, history, context_docs, api_key):
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-1.5-flash")
    profil = PROFILS[profil_key]

    context = "\n\n".join(context_docs) if context_docs else "Aucun document disponible."
    hist_text = "\n".join([f"{m['role'].capitalize()} : {m['content']}" for m in history[-6:]])

    prompt = f"""{profil['system']}

Extraits de documents pertinents :
{context}

Historique de la conversation :
{hist_text}

Question de l'utilisateur : {user_input}

RÃ©ponse (en franÃ§ais) :"""

    response = model.generate_content(prompt)
    return response.text

def load_folder_docs(api_key):
    folder = "docs"
    all_chunks = []
    filenames = []
    if not os.path.exists(folder):
        return [], []
    for filename in os.listdir(folder):
        filepath = os.path.join(folder, filename)
        ext = filename.lower().split(".")[-1]
        text = ""
        if ext == "pdf":
            text = extract_text_from_pdf(filepath)
        elif ext in ["docx", "doc"]:
            text = extract_text_from_docx(filepath)
        if text.strip():
            chunks = chunk_text(text)
            all_chunks.extend(chunks)
            filenames.append(filename)
    return all_chunks, filenames

def load_uploaded_docs(uploaded_files):
    all_chunks = []
    for uf in uploaded_files:
        suffix = "." + uf.name.split(".")[-1].lower()
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uf.read())
            tmp_path = tmp.name
        text = ""
        if suffix == ".pdf":
            text = extract_text_from_pdf(tmp_path)
        elif suffix in [".docx", ".doc"]:
            text = extract_text_from_docx(tmp_path)
        os.unlink(tmp_path)
        if text.strip():
            all_chunks.extend(chunk_text(text))
    return all_chunks

# â”€â”€ Init session â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_session():
    defaults = {
        "messages": [], "profil": None, "collection": None,
        "docs_loaded": False, "api_key_ok": False,
        "preloaded_files": [], "preload_done": False
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

# â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    init_session()
    st.title("ğŸ’» Conseiller MÃ©tiers du NumÃ©rique")
    st.caption("Assistant IA de conseil et coaching sur les mÃ©tiers du numÃ©rique")

    with st.sidebar:
        st.header("âš™ï¸ Configuration")

        # ClÃ© API
        api_key = None
        try:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.session_state.api_key_ok = True
            st.success("âœ… ClÃ© API Gemini active")
        except:
            api_key = st.text_input("ğŸ”‘ ClÃ© API Google Gemini", type="password", placeholder="AIza...")
            if api_key:
                st.session_state.api_key_ok = True
                st.success("âœ… ClÃ© API configurÃ©e")

        # PrÃ©-chargement docs/
        if api_key and not st.session_state.preload_done:
            with st.spinner("ğŸ“š Chargement des documents..."):
                try:
                    chunks, files = load_folder_docs(api_key)
                    if chunks:
                        st.session_state.collection = build_vectorstore(chunks, api_key)
                        st.session_state.docs_loaded = True
                        st.session_state.preloaded_files = files
                except Exception as e:
                    st.warning(f"Erreur docs : {e}")
                finally:
                    st.session_state.preload_done = True

        st.divider()
        st.subheader("ğŸ“„ Base de connaissance")
        if st.session_state.preloaded_files:
            st.success(f"âœ… {len(st.session_state.preloaded_files)} document(s) chargÃ©(s)")
            for f in st.session_state.preloaded_files:
                st.caption(f"ğŸ“ {f}")
        else:
            st.info("Dossier `docs/` vide â€” mode LLM seul")

        with st.expander("â• Ajouter des documents"):
            uploaded_files = st.file_uploader("PDF / Word", type=["pdf", "docx", "doc"], accept_multiple_files=True)
            if uploaded_files and api_key:
                if st.button("ğŸ“¥ Indexer", use_container_width=True):
                    with st.spinner("Indexation..."):
                        try:
                            chunks = load_uploaded_docs(uploaded_files)
                            if chunks:
                                st.session_state.collection = build_vectorstore(chunks, api_key)
                                st.session_state.docs_loaded = True
                                st.success(f"âœ… {len(chunks)} extraits indexÃ©s !")
                        except Exception as e:
                            st.error(f"Erreur : {e}")

        st.divider()
        st.subheader("ğŸ‘¤ Profil dÃ©tectÃ©")
        if st.session_state.profil:
            p = PROFILS[st.session_state.profil]
            st.markdown(f'<span class="profile-badge {p["badge_class"]}">{p["label"]}</span>', unsafe_allow_html=True)
        else:
            st.info("Auto-dÃ©tectÃ© Ã  la 1Ã¨re question")

        if st.button("ğŸ”„ RÃ©initialiser la conversation", use_container_width=True):
            st.session_state.messages = []
            st.session_state.profil = None
            st.rerun()

        st.divider()
        st.caption("POC â€” Chatbot MÃ©tiers du NumÃ©rique\nğŸ¤– Gemini Flash 2.0 + RAG")

    # Zone principale
    if not st.session_state.api_key_ok:
        st.info("ğŸ‘ˆ Entrez votre clÃ© API Gemini dans le panneau de gauche.")
        st.markdown("ClÃ© gratuite sur [aistudio.google.com](https://aistudio.google.com)")
        return

    # Message d'accueil
    if not st.session_state.messages:
        with st.chat_message("assistant"):
            st.markdown("""Bonjour ! ğŸ‘‹ Je suis votre **conseiller en mÃ©tiers du numÃ©rique**.

Je suis lÃ  pour vous aider Ã  :
- ğŸ“ DÃ©couvrir les mÃ©tiers du numÃ©rique selon votre profil
- ğŸ’¡ Obtenir des conseils personnalisÃ©s d'orientation
- ğŸš€ Construire votre projet professionnel dans le secteur tech

**Dites-moi qui vous Ãªtes et ce que vous recherchez !**
*(ex : "Je suis Ã©tudiant en terminale et je cherche ma voie dans l'informatique")*""")

    # Historique
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Input
    if user_input := st.chat_input("Posez votre question..."):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("RÃ©flexion en cours..."):
                try:
                    # DÃ©tection profil
                    if not st.session_state.profil:
                        profil = detect_profil(user_input, api_key)
                        st.session_state.profil = profil
                        p = PROFILS[profil]
                        st.markdown(f'<span class="profile-badge {p["badge_class"]}">Profil dÃ©tectÃ© : {p["label"]}</span>', unsafe_allow_html=True)

                    # Recherche RAG
                    context_docs = []
                    if st.session_state.collection:
                        context_docs = search_docs(st.session_state.collection, user_input, api_key)

                    # GÃ©nÃ©ration rÃ©ponse
                    answer = generate_response(
                        user_input,
                        st.session_state.profil,
                        st.session_state.messages[:-1],
                        context_docs,
                        api_key
                    )
                    st.markdown(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})

                except Exception as e:
                    err_msg = f"âŒ Erreur : {str(e)}"
                    st.error(err_msg)
                    st.session_state.messages.append({"role": "assistant", "content": err_msg})

if __name__ == "__main__":
    main()
